{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom tensorflow import keras","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-16T18:22:18.642185Z","iopub.execute_input":"2023-10-16T18:22:18.642623Z","iopub.status.idle":"2023-10-16T18:22:30.863588Z","shell.execute_reply.started":"2023-10-16T18:22:18.642587Z","shell.execute_reply":"2023-10-16T18:22:30.862625Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Load the data from CSV and randomly split the data into a training and test sets by holding 30% of the data for testing","metadata":{}},{"cell_type":"code","source":"\nconcrete_data = pd.read_csv('/kaggle/input/concrete-data/concrete_data.csv')\nX = concrete_data.iloc[:, :-1].values \ny = concrete_data.iloc[:, -1].values   \n\nX_normalized = (X - np.mean(X, axis=0)) / np.std(X, axis=0) # Normalize the data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-16T18:22:30.865011Z","iopub.execute_input":"2023-10-16T18:22:30.866371Z","iopub.status.idle":"2023-10-16T18:22:30.904623Z","shell.execute_reply.started":"2023-10-16T18:22:30.866336Z","shell.execute_reply":"2023-10-16T18:22:30.903709Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Train the model on the training data using 50 epochs","metadata":{}},{"cell_type":"code","source":"\n# List to store all the mean squared errors\nmse_list = []\n\n# Repeat the process 100 times\nfor _ in range(100):\n    \n    # Model with three hidden layers\n    model = keras.Sequential([\n        keras.layers.Dense(10, activation='relu', input_shape=(X_train.shape[1],)),\n        keras.layers.Dense(10, activation='relu'),\n        keras.layers.Dense(10, activation='relu'),\n        keras.layers.Dense(1)\n    ])\n\n    model.compile(optimizer='adam', loss='mean_squared_error')\n\n    # Train the model\n    model.fit(X_train, y_train, epochs=100, verbose=0)\n\n    # Evaluate the model \n    y_pred = model.predict(X_test)\n    mse = mean_squared_error(y_test, y_pred)\n    mse_list.append(mse)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-16T18:22:30.905836Z","iopub.execute_input":"2023-10-16T18:22:30.906320Z","iopub.status.idle":"2023-10-16T18:30:28.751141Z","shell.execute_reply.started":"2023-10-16T18:22:30.906292Z","shell.execute_reply":"2023-10-16T18:30:28.750337Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 2ms/step\n10/10 [==============================] - 0s 1ms/step\n10/10 [==============================] - 0s 1ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Report the mean and the standard deviation of the mean squared errors","metadata":{}},{"cell_type":"code","source":"mean_mse = np.mean(mse_list)\nstd_mse = np.std(mse_list)\n\nprint(mean_mse)\nprint(std_mse)","metadata":{"execution":{"iopub.status.busy":"2023-10-16T18:30:28.753473Z","iopub.execute_input":"2023-10-16T18:30:28.754139Z","iopub.status.idle":"2023-10-16T18:30:28.760890Z","shell.execute_reply.started":"2023-10-16T18:30:28.754100Z","shell.execute_reply":"2023-10-16T18:30:28.759921Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"108.23150111284345\n138.9662144981833\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Increasing the number of hidden layers can enhance the model's ability to capture complex patterns in the data,  resulting in reduced mean squared error values.","metadata":{}}]}